{"/1-setting-hellobatch":{"title":"1 Setting Hellobatch","data":{"setting--hellospring-batch#Setting + Hello,Spring Batch":"","setting#Setting":"프로젝트 셋업\nstart.spring.io 에서 lombok, mysql, spring-batch 등을 선택합니다.\nDatabase\nintellij 내에서 localhost:3306 연결하고, 접속 테스트시 에러나면, Timezone 세팅하는 버튼을 클릭해서 timezone 을 세팅합니다.\ndatabase 생성\ncreate database spring_batch;","hello-spring-batch#Hello, Spring Batch":"간단한 HelloJob 을 생성하고 구동함\nJob\n배치의 실행 단위\nJobBuilderFactory\n스프링 배치 설정에서 Bean 으로 등록되어 있는 객체\nRunIdIncrementer\nJob 을 실행할 때마다 파라미터 ID 를 자동으로 생성해주는 클래스\njobBuilderFactory.get(\"helloJob\")\nJob name 을 helloJob 으로 지었는데, job name 은 Spring Batch 를 실행할 수 있는 Key 역할을 한다.\nstart(Step)\njob 실행시 최초로 실행될 클래스를 지정하는 메서드\nStep\nJob 의 실행 단위\n하나의 Job 은 1개 이상의 Step 을 가질 수 있습니다.\nStep 역시 Job 처럼 Bean 으로 만들어야 합니다.\nJob 과 Step 에 대해서는 뒤에서 자세히 다룹니다.\nchunk 기반 tasklet 실행\n예제 참고. tasklet 기반 예제를 굳이 여기에 적으면 낭비가 심해서 생략합니다.\nTODO : 예제 코드 링크 추가할 것\n애플리케이션 실행시 HelloJob 배치가 실행됩니다. 만약 다른 Job 이 있는 상태에서 이 HelloJob 배치를 실행하면 모든 Job 이 실행된다.모든 Job 을 실행하는 것이 아니라 특정 Job 만 실행하려 할 경우 아래 설정을 해준다.Run/Debug Configuration\nEdit Configurations ...\nBuild and run > Modify options 클릭\nJava > Program arguments 선택\nConfigurations 창에서 아래의 옵션을 입력\n--spring.batch.job.names={실행할 Job name}\nApply > Ok\n위와 같이 설정해주면 Program Argument 로 지정한 Batch 만 실행하겠다는 설정이되어서 실행 시 Program Argument 로 지정한 Batch 만 실행되게 된다.그리고 직접 인자값으로 지정하지 않은 Job 까지 실행되는 것을 막으려면 application.yml 파일 내에 아래와 같이 설정해준다.\nspring.batch.job.names: ${job.name.NONE}\nspring:\r\n  batch:\r\n    job:\r\n      names: ${job.name:NONE}\n또는 아래와 같이 설정해준다.\n(Spring Boot Configuration Processor 가 추천해준 속성이다.)\nspring.batch.job.enabled: ${spring.batch.job.names:NONE}\nspring:\r\n  batch:\r\n    job:\r\n      enabled: ${spring.batch.job.names:NONE}","job-step#Job, Step":"Job\nBatch 의 실행 단위\nStep\nJob 의 실행 단위"}},"/2.1-architecture":{"title":"2.1 Architecture","data":{"기본-구조#기본 구조":"참고 : https://docs.spring.io/spring-batch/docs/4.3.5/reference/html/job.html","joblauncher-jobrepository-job-chunk-tasklet--itemreader-itemprocessor-itemwriter#JobLauncher, JobRepository, Job, Chunk, Tasklet,  ItemReader, ItemProcessor, ItemWriter":"","joblauncher#JobLauncher":"Bean 을 생성만 했을 뿐인데 Batch가 실행될 수 있는데, 원하지 않는 잡들이 실행되는 것을 막으려면 application.yml 에 아래의 설정을 추가하면 됩니다.\nspring.batch.job.enabled: ${spring.batch.job.names:NONE}\nspring.batch.job.names: ${job.name.NONE}\nSpring Batch 는 Job 타임에 Bean 이 생성되면 JobLauncher 객체에 의해서 Job 을 수행합니다.\nJobLauncher 는 Job 을 실행하고, Job 은 Step 을 수행합니다.","jobrepository#JobRepository":"DB or Memory 에 스프링 배치가 실행될 수 있도록 배치의 메타데이터를 관리하는 역할을 수행","job#Job":"배치의 실행단위 (중요!!)\nJob 은 JobLauncher 에 의해 실행됩니다.\nJob 은 여러 개의 Step 을 실행하며, Flow 를 관리할 수 있습니다.\ne.g. Step A → on 조건 B → Step B\n이렇게 여러개의 Step 을 Flow 로 실행하는 것을 Job Flow 라고 부릅니다.","chunk-tasklet#Chunk, Tasklet":"예를 들어 100만건의 데이터를 처리해야 하는 작업이 있다고 하자.만약 100만건의 데이터에 대해 원하는 작업을 할 때 컴퓨터 자원에 문제가 없다면?\nTasklet 처리를 해도 무방합니다.\n만약 100만건의 데이터에 대해 원하는 작업을 할 때 컴퓨터 자원에 문제가 있다면?\nChunk 기반의 처리를 하는 것이 권장됩니다.\n1만건 Size 의 Chunk 를 만들어서 이 Chunk 를 페이징 기반의 처리를 하는 방식으로 전환한다면, 메모리가 부족해져서 프로그램이 멈추는 현상 등을 방지할 수 있습니다.\n뒤에서 정리하겠지만, 가급적이면 페이징 사이즈는 Chunk Size 와 동일하게 하는 것이 권장됩니다.\nTasklet 도 나눠서 처리하는 것을 수동으로 작성할 수 있지만 대용량 데이터를 처리시에는 Chunk 기반 처리방식이 더 활용성이 높고 ItemReader, ItemProcessor, ItemWriter 등을 통해서 딱딱 떨어지게끔 처리하면서 중간에 어디까지 실행했는지에 대한 Context 를 저장하거나 이력을 보관할 수 있기에 가급적이면 Chunk 기반의 처리를 하도록 작성하는 것을 추천되는 편입니다.","itemreader-itemprocessor-itemwriter#ItemReader, ItemProcessor, ItemWriter":"ItemReader\n배치 처리를 해야 하는 대상 객체를 읽어들이는 역할\ne.g. FlatFileItemReader, JdbcPagingItemReader, JpaPagingItemReader\nItemProcessor\nItemReader 로부터 읽어들인 데이터를 ItemWriter 로 보내기 전에 Processing 또는 Filtering 작업을 수행하는 역할\nnull 을 리턴하면 그 데이터는 필터링 되어 ItemWriter 로는 전달되지 않습니다.\nItemProcessor 는 Optional 이며, 생략가능하다. 즉, Step 구성시 ItemReader, ItemWriter 로만 구성하는 것도 가능합니다.\nItemWriter\nItemProcessor 로부터 전달된 객체를 이용해서 데이터를 저장하거나, 메시지큐에 데이터를 전송하는 등과 같은 Write 하는 역할을 담당합니다.","sprng-batch-tables#Sprng Batch Tables":"","table-명세#Table 명세":"Spring Batch 는 배치 실행 기록과, 배치 실행 결과를 저장하는 테이블들을 가지고 있습니다. 이 테이블들을 Meta 테이블이라고 흔히 이야기합니다.참고 : https://docs.spring.io/spring-batch/reference/_images/meta-data-erd.png\nBATCH_JOB_INSTANCE\n위의 ERD 에서 BATCH_JOB_INSTANCE 테이블을 자세히 보면 JOB_NAME, JOB_KEY 이 보입니다.\n배치 실행 시에는 JOB_NAME, JOB_KEY 를 기준으로 하나의 row 가 생성되는데, 이 JOB_NAME, JOB_KEY 는 중복을 허용하지 않습니다.\n즉, JobInstance 의 생성기준, BATCH_JOB_INSTANCE 테이블의 로우(ROW) 생성기준은 JOB_NAME, JOB_KEY이며 JOB_NAME, JOB_KEY은 중복되면 안됩니다.\nJOB_KEY 값은 BATCH_JOB_EXECUTION_PARAMS 테이블 내에 저장되는 Parameter 를 나열해서 암호화해서 저장합니다.\nBATCH_JOB_EXECUTION_PARAMS\nJob 을 실행할 때 사용된(주입된) Parameter를 저장하는 테이블입니다.\nBATCH_JOB_EXECUTION\nJob 의 시작시각, Job의 종료시각, Job 의 상태 를 기록하기 위한 테이블입니다.\nJob 이 실행되는 시점에 BATCH_JOB_EXECUTION 테이블에 데이터가 추가됩니다.\nBATCH_JOB_EXECUTION_CONTEXT\nJob 이 실행되는 동안 공유되어야 하는 데이터를 직렬화 해서 저장합니다.\nBATCH_STEP_EXECUTION\nStep 이 실행되는 동안 필요한 데이터와 실행 결과를 저장합니다.\nBATCH_STEP_EXECUTION_CONTEXT\nStep 이 실행되는 동안 공유되어야 하는 데이터를 직렬화해서 저장합니다.\n이 테이블에서는 하나의 Step 이 실행되는 동안 데이터를 공유합니다.\n이 테이블에서는 Step 간에 테이블의 데이터를 공유하지 않으며, Step 간에 데이터를 공유하는 것은 BATCH_JOB_EXECUTION_CONTEXT 에서 데이터를 공유할 수 있습니다.","schema-스크립트-경로#Schema 스크립트 경로":"테이블 ddl 이 있는 곳의 경로는 spring-batch-core/org.springframework/batch/core* 입니다.intellij 에서는 아래와 같이 찾으실 수 있습니다.Project View > External Libraries 에서 spring-batch-core 를 검색합니다.\n검색결과로 spring-batch-core-a.b.c.jar 파일이 검색되었음을 확인 가능합니다.\n스크롤을 내려보면 아래 그림처럼 schema-{db 타입}.sql 파일들이 나타나는 것을 볼 수 있습니다.위와 같이 Spring Batch 팀에서는 Spring Batch 라이브러리에 필요한 스키마들을 class path 내에서 찾을 수 있도록 제공해주고 있습니다.","batch-table-초기화-옵션#batch table 초기화 옵션":"batch 테이블 초기화 옵션은 application.yml 파일에 아래와 같이 설정할 수 있습니다.\nspring:\r\n  batch:\r\n    initialize-schema: never\n이 속성에는 아래와 같은 값들을 지정 가능합니다.\nspring.batch.initialize-schema=never\n배치 잡 기동시 스키마 초기화 스크립트를 실행하지 않는 방식입니다.\n주로 Production 레벨에서 사용하는 옵션입니다.\nspring.batch.initialize-schema=always\n배치 잡 기동시 스키마 초기화 스크립트를 항상 수행하도록 지정하는 방식입니다.\n주로 개발환경에서 사용하는 옵션입니다.\nspring.batch.initialize-schema=embedded\n배치 잡 기동시 스키마 초기화 스크립트를 h2 와 같은 embedded (내장) Database 를 사용할 때에만 사용할 수 있도록 지정하는 방식입니다.\n주로 개발환경에서 사용하는 옵션입니다.","객체-매핑#객체 매핑":"참고 : https://terasoluna-batch.github.io/guideline/5.0.0.RELEASE/en/Ch02_SpringBatchArchitecture.html#Ch02_SpringBatchArch_Detail_ProcessFlow\nJobInstance 객체 : BATCH_JOB_INSTANCE 테이블에 매핑\nJobExecution 객체 : BATCH_JOB_EXECUTION 테이블에 매핑\nJobParameters 객체 : BATCH_JOB_EXECUTION_PARAMS 테이블에 매핑\nExecutionContext 객체 : BATCH_JOB_EXECUTION_CONTEXT 테이블에 매핑","jobinstance-jobparameters-jobexecution#JobInstance, JobParameters, JobExecution":"JobInstanceJobInstance 는 BATCH_JOB_INSTANCE 테이블과 매핑되는 테이블입니다. JOB_INSTANCE 테이블의 주요 컬럼으로는 JOB_NAME, JOB_KEY 가 있습니다. 그리고 JOB_NAME, JOB_KEY 를 기준으로 하나의 row 가 생성되는데, 이 JOB_NAME, JOB_KEY 는 중복을 허용하지 않습니다. 즉, JobInstance 의 생성기준, BATCH_JOB_INSTANCE 테이블의 로우(ROW) 생성기준은 JOB_NAME, JOB_KEY이며 JOB_NAME, JOB_KEY은 중복되면 안됩니다.\nJobParameter, JobExecutionJobInstance 를 새로 생성할지에 대한 기준은 JobParameter 의 중복 여부로 결정합니다.\n같은 Parameter 로 Job을 다시 실행하면 이미 생성된 JobInstance 를 실행합니다.\n다른 Parameter 로 Job을 다시 실행하면 새로운 JobInstance 를 실행합니다.\nJobExecution 은 JobInstance 재실행 여부와 상관 없이 항상 새롭게 생성됩니다.e.g.\nJob 실행시 12월 1일 이라는 date parameter 를 처음 받아서 실행했다면?\njob_instance_id = k 에 해당하는 신규 JobInstance 실행\nJob 실행시 12월 2일 이라는 date parameter 를 처음 받아서 실행했다면?\njob_instance_id = m 에 해당하는 신규 JobInstance 실행\nJob 실행시 12월 2일 이라는 date parameter 를  한번 더 받아서 실행했다면?\njob_instance_id = m 에 해당하는 JobInstance 를 재실행","runidincmenter#RunIdIncmenter":"Job 을 항상 새로운 JobInstance로 실행되게끔 해야 할 경우가 있습니다. 이런 경우 RunIdIncrementer 를 사용합니다. RunIdIncrementer 를 사용하면 run.id 라는  job_key 에 대해 항상 다른 job_name 값이 지정되어서 항상 새로운 JobInstance 로 실행됩니다.","stepexecution-executioncontext#StepExecution, ExecutionContext":"StepExecution : BATCH_STEP_EXECUTION 테이블에 매핑되는 객체ExecutionContext : BATCH_STEP_EXECUTION_CONTEXT 테이블에 매핑되는 객체\nJOB, STEP 에 모두 매핑될 수 있는 객체입니다.\n참고) BATCH_JOB_EXECUTION_CONTEXT 테이블은 ExecutionContext 객체와 매핑됩니다.","요약#요약":"하나의 Job 은 항상 같은 파라미터로 새롭게 실행하는 것은 불가능합니다.ExecutionContext 는 Job, Step 의 Context 를 관리하는 객체입니다.\nExecutionContext 를 통해서 데이터를 공유할 수 있습니다.\nJobExecutionContext\nJob 내에서만 데이터를 공유할 수 있습니다\nJobExecutionContext 는 Step 끼리 데이터를 공유할 수 있습니다.\nStepExecutionContext\nStep 내에서만 데이터를 공유할 수 있습니다.\nStep 내에서만 공유하다는 의미이며, 다른 Step 과는 공유가 불가능합니다.","executioncontext#ExecutionContext":"Job 내에서 서로 다른 Step A, B 가 실행되게끔 Job 을 구성했다고 하겠습니다.\nTODO : 예제 추가 필요\nJobExecutionContext\nJob 내에서만 데이터를 공유할 수 있습니다\nJobExecutionContext 는 Step 끼리 데이터를 공유할 수 있습니다.\nStepExecutionContext\nStep 내에서만 데이터를 공유할 수 있습니다.\nStep 내에서만 공유하다는 의미이며, 다른 Step 과는 공유가 불가능합니다."}},"/chunk-oriented-tasklet--chunk-provider--chunk-processor":{"title":"Chunk Oriented Tasklet  Chunk Provider  Chunk Processor","data":{"chunkorientedtasklet-chunkprovider-chunkprocessor#ChunkOrientedTasklet, ChunkProvider, ChunkProcessor":"","참고자료#참고자료":"Spring Batch : ChunkOrientedTaskLet, ChunkProvider, ChunkProcessor\nSpring Batch 에서의 Transaction 에 대한 자료들을 찾아보던 중 위의 글을 발견해서 정리를 합니다.위의 자료는 인프런 정수원님의 강의를 듣고 정리한 블로그 문서라고 합니다.저 역시 위의 강의를 들어보고 싶지만, 이번달 생활비가 예산 초과여서 이번 달에는 결제를 못할 것 같고 다음달에 꼭 들어볼 생각으로 장바구니에만 추가해뒀습니다. 강의 목차를 보니 꽤 충실한 내용같아서 얼른 구매해서 강의를 들어보고 싶다는 생각을 하게 되네요!!","목차#목차":"ChunkOrientedTasklet 이란, Chunk 단위 Transaction\nChunkOrientedTasklet 의 동작 방식\nChunkOrientedTasklet 의 주요 API\nChunkOrientedTasklet 의 Chunk 처리시 예외발생으로 인한 재시도 방식\nChunkProvider::provide()\nChunkProcessor::process()","1-chunkorientedtasklet이란-chunk-단위-transaction#1. ChunkOrientedTasklet이란, Chunk 단위 Transaction":"ChunkOrientedTaskletChunkOrientedTasklet 은 Spring Batch 에서 제공하는 Tasklet 인터페이스의 구현체입니다. 내부적으로는 Chunk 를 가지고 있기에 Chunk 기반의 프로세스 처리가 가능하며, ItemReader, ItemProcessor, ItemWriter 를 가지고 있기에 ItemReader, ItemProcessor, ItemWriter 을 활용해서 Chunk Process 처리를 합니다.내부적으로는 Repeat Template 을 가지고 있습니다.그리고 ChunkOrientedTasklet 은 Chunk 단위로 트랜잭션을 커밋합니다.\nChunk 단위 TransactionChunkOrientedTasklet 은 Chunk 단위로 트랜잭션을 커밋합니다.ChunkOrientedTasklet 은 ChunkOrientedTasklet 이 실행될 때마다 새로운 트랜잭션이 생성된 상태에서 처리가 이뤄집니다. 이 트랜잭션 단위 내에서는 Exception 이 발생한다면 Rollback 이 이뤄집니다. 참고로 예외 발생시 예외 발생 전에 이미 Commit 이 완료된 Chunk 는 그대로 유지됩니다. ChunkOrientedTasklet 은 Chunk 단위로 트랜잭션을 커밋하기 때문에 이렇게 Chunk 단위 내에서 예외가 발생하면 그 Chunk 에서 처리하던 Transaction 은 Rollback 을 하게 됩니다.Chunk 처리 중 예외가 발생해서 재시도를 해야 할 경우, 데이터를 다시 읽지 않고 버퍼(=ChunkContext)에 담아둔 데이터를 가져옵니다. 이 재시도를 할 때 내부적으로 어떻게 하는지, 데이터를 새로 읽어오는지 에 대해서는 아래의 4. ChunkOrientedTasklet 의 Chunk 처리시 예외 발생으로 인한 재시도 방식 섹션에서 정리합니다.\n4. ChunkOrientedTasklet 의 Chunk 처리시 예외 발생으로 인한 재시도 방식\n실패 후 재시도시 데이터를 새로 읽어올 경우 기존 데이터와 다를 수 있기에 내부적으로 ChunkContext 라고 불리는 버퍼를 사용하는데, 이 버퍼에 데이터를 어떻게 저장하는지 등과 관련된 내용을 다룹니다.","2-chunkorientedtasklet-의-동작-방식#2. ChunkOrientedTasklet 의 동작 방식":"execute()\nTaskletStep 은 execute() 메서드를 호출해서 ChunkOrientedTasklet 을 실행합니다.\nChunkOrientedTasklet::provide()\nItemReader 를 통해서 Chunk에 저장할 item을 읽어옵니다.\n이때 Chunk 내에서 처음 불러오는 것이라면 트랜잭션을 열어줍니다.\n이 데이터는 ChunkSize 만큼의 데이터입니다.\nChunkOrientedTasklet::process(inputs)\nItemReader가 읽어들인 InputChunk 를 ChunkProcessor::process() 메서드에 전달됩니다.\nItemProcessor::process()\nChunkProcessor 에서부터 Input Chunk 는 ItemProcessor::process() 에서 단건으로 처리됩니다.\nItemProcessor::process() 의 결과는 OutputChunk에 하나씩 들어갑니다.\nItemWriter::write(items)\nOutput Chunk 가 ItemWriter 에 전달되며, 이 OutputChunk 는 ItemWriter 에서는 배치(덩어리)처리 됩니다.","3-chunkorientedtasklet-의-주요-api#3. ChunkOrientedTasklet 의 주요 API":"<I,O> chunk(int chunkSize)\nchunkSize 설정\n다르게 이야기하면, commit 인터벌을 의미합니다.\n스프링 배치의 ChunkOrientedTasklet 은 chunk 단위로 트랜잭션을 새로 열기 때문에 commit 인터벌 이라는 말로 설명할 수 있습니다.\n<I,O> chunk(CompletionPolicy)\nChunk Process 를 완료하기 위한 설정 클래스를 지정합니다.\nreader()\nItemReader 구현체를 지정하는 메서드 입니다.\nwriter()\nItemWriter 구현체를 지정하는 메서드 입니다.\nprocessor()\nItemProcessor 구현체를 지정하는 메서드입니다.\nOptional 하게 지정가능하며, ItemProcessor 가 필요없다면 지정해주지 않아도 됩니다.\nstream()\n재시작 데이터를 관리하는 콜백에 대한 stream 을 지정하는 메서드 입니다.\nreaderIsTransactionalQueue()\nItem 이 JMS 와 같은 트랜잭션 트랜잭션 외부에서 읽혀지고 캐시할 것인지를 지정하는 메서드입니다.\nlistener\n리스너를 지정할 때 사용하는 메서드입니다.\nbuild\nbuild 메서드를 통해 객체를 생성합니다.","4-chunkorientedtasklet-의-chunk-처리시-예외-발생으로-인한-재시도-방식#4. ChunkOrientedTasklet 의 Chunk 처리시 예외 발생으로 인한 재시도 방식":"Chunk 처리 중 예외가 발생해서 재시도를 해야 할 경우, 데이터를 다시 읽지 않고 버퍼(=ChunkContext)에 담아둔 데이터를 가져옵니다.","내부-동작#내부 동작":"","chunkproviderprovide#ChunkProvider::provide()":"ChunkProvider::provide()Iterator 패턴 기반인 RepeatOperations 를 기반으로 iterate 를 수행. 내부적으로는 doInIteration 클래스를 구현.Chunk 는 provide() 메서드가 호출될 때마다 새롭게 생성ItemReader 의 read(Contributuion, inputs) 를 통해 소스로부터 item 을 읽어온다.읽어온 item 이 없을 경우에는 종료하는데 inputs.setEnd() 를 호출해서 종료읽어온 item 이 있는 경우 input Chunk 인 inputs 에 넣어준다. (inputs.add(item) )","chunkprocessor#ChunkProcessor":"ChunkProcessor interface 는 process() 메서드를 제공합니다.\npackage org.springframework.batch.core.step.item;\r\n\r\nimport org.springframework.batch.core.StepContribution;\r\n\r\npublic interface ChunkProcessor<I> {\r\n  void process(StepContribution var1, Chunk<I> var2) throws Exception;\r\n}\n이 ChunkProcessor interface 를 구현하는 구현체들은 아래와 같은 구현체들이 있습니다.\nFaultTolerantChunkProcessor\nJsrChunkProcessor\nJsrFaultTolerantChunkProcessor\nSimpleChunkProcessor\n이번 문서에서는 위의 구현체 들 중 SimpleChunkProcessor 클래스의 process() 메서드의 동작을 살펴봅니다.","simplechunkprocessorprocess#SimpleChunkProcessor::process()":"public class SimpleChunkProcessor<I, O> implements ChunkProcessor<I>, InitializingBean {\r\n    // ...\r\n    public final void process(StepContribution contribution, Chunk<I> inputs) throws Exception {\r\n        this.initializeUserData(inputs);\r\n        \r\n        if (!this.isComplete(inputs)) {\r\n            // (1)\r\n            Chunk<O> outputs = this.transform(contribution, inputs); \r\n            // (2) \r\n            contribution.incrementFilterCount(this.getFilterCount(inputs, outputs)); \r\n            // (3)\r\n            this.write(contribution, inputs, this.getAdjustedOutputs(inputs, outputs));\r\n        }\r\n    }\r\n}\n(1) : transform(contribution, inputs);\ntransform() 메서드는 nputChunk 를 itemProcessor 에 전달해서 Output Chunk 를 만들어오는 역할을 수행합니다.\ntransform() 메서드는 아래에서 설명합니다.\n(2) : incrementFilterCount()\nProcessor 의 Process 과정에서 filter 에 부합하는 유효한 값들만 필터링하며 카운트를 합니다.\n(3) : write(contribution, inputs, this.getAdjustedOutputs(inputs, outputs));\n(1), (2) 에서 구한 OutputChunk 를 ItemWriter 에 전달해줍니다.\nwrite() 메서드는 아래에서 설명합니다.","simplechunkprocessortransform#SimpleChunkProcessor::transform()":"참고 : SimpleChunkProcessor\n위에서 살펴본 ChunkProcessor::process() 메서드는 transform() 메서드를 호출하고 있는데, transform() 메서드의 내부 정의는 아래와 같이 정의되어 있습니다.\npublic class SimpleChunkProcessor<I, O> implements ChunkProcessor<I>, InitializingBean {\r\n    // ...\r\n\r\n    protected Chunk<O> transform(StepContribution contribution, Chunk<I> inputs) throws Exception {\r\n        Chunk<O> outputs = new Chunk(); // (2)\r\n        Chunk<I>.ChunkIterator iterator = inputs.iterator();\r\n\r\n        while(iterator.hasNext()) {\r\n          I item = iterator.next();\r\n          Timer.Sample sample = BatchMetrics.createTimerSample();\r\n          String status = \"SUCCESS\";\r\n\r\n          Object output;\r\n          try {\r\n            output = this.doProcess(item); // (1)\r\n          } catch (Exception var13) {\r\n            inputs.clear();\r\n            status = \"FAILURE\";\r\n            throw var13;\r\n          } finally {\r\n            this.stopTimer(sample, contribution.getStepExecution(), \"item.process\", status, \"Item processing\");\r\n          }\r\n\r\n          if (output != null) {\r\n            outputs.add(output); // (2)\r\n          } else {\r\n            iterator.remove(); // (2)\r\n          }\r\n        }\r\n\r\n        return outputs; // (2)\r\n  \t}\r\n}\n(1)\ntransform 메서드는 while 문을 통해서 doProcess(item) 을 itemSize 만큼 처리해줍니다.\n즉, item 을 하나씩 단건으로 Processing 합니다.\n(2)\n새로운 Chunk<O> outputs 객체를 만든 후, 이 outputs에 처리 결과를 add() 하거나, remove() 해서 처리 대상 데이터에서 필터링합니다.\n그리고 이 Chunk<O> outputs 을 return 합니다.","simplechunkprocessorwrite#SimpleChunkProcessor::write()":"public class SimpleChunkProcessor<I, O> implements ChunkProcessor<I>, InitializingBean {\r\n    // ...\r\n    \r\n    protected void write(StepContribution contribution, Chunk<I> inputs, Chunk<O> outputs) throws Exception {\r\n        Timer.Sample sample = BatchMetrics.createTimerSample();\r\n        String status = \"SUCCESS\";\r\n\r\n        try {\r\n          // (1)\r\n          this.doWrite(outputs.getItems());\r\n        } catch (Exception var10) {\r\n          inputs.clear();\r\n          status = \"FAILURE\";\r\n          throw var10;\r\n        } finally {\r\n          this.stopTimer(sample, contribution.getStepExecution(), \"chunk.write\", status, \"Chunk writing\");\r\n        }\r\n\r\n        contribution.incrementWriteCount(outputs.size());\r\n\t}\r\n    \r\n    // ...\r\n    protected final void doWrite(List<O> items) throws Exception {\r\n        if (this.itemWriter != null) {\r\n            try {\r\n                this.listener.beforeWrite(items);\r\n                // (2)\r\n                this.writeItems(items);\r\n                this.doAfterWrite(items);\r\n            } catch (Exception var3) {\r\n                this.doOnWriteError(var3, items);\r\n                throw var3;\r\n\t\t\t}\r\n        }\r\n\t}\r\n}\n(1)\ndoWrite() 메서드에 outputs.getItems() 를 넘겨줍니다. outputs.getItems() 는 Output Chunk 의 List 입니다.\n(2)\ndoWrite(...) 메서드에서는 writeItems(items) 메서드에 items 전체를 넘겨줍니다.\n이로 미루어볼수 있는 것은 ItemWriter 는 데이터를 배치단위(덩어리)로 한번에 처리한 다는 사실을 알수 있습니다."}},"/":{"title":"Introduction","data":{}}}